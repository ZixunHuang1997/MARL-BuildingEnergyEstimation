{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e59cb24-fdd9-46ac-98e4-a5c6a725a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from model.VQAE import VQAE\n",
    "from utils import device, add_noise\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from data.FloorPlanLoader import *\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import json\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "USE_MULTISCALE = True\n",
    "USE_MULTITASK = True\n",
    "\n",
    "#Reproducability Checks:\n",
    "random.seed(0) #Python\n",
    "torch.manual_seed(0) #Torch\n",
    "np.random.seed(0) #NumPy\n",
    "\n",
    "import re\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import imageio\n",
    "from torchvision.utils import save_image\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import csv\n",
    "import numpy\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c9127f-bb8d-4427-ade4-e5c7d61ad337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "device = 'cpu'\n",
    "batch_size = 128\n",
    "n_hiddens = 32\n",
    "n_residual_hiddens = 32\n",
    "n_residual_layers = 1\n",
    "embedding_dim = 64\n",
    "n_embeddings = 218\n",
    "beta = .25\n",
    "lr = 3e-3\n",
    "noise=False\n",
    "noise_weight=0.05\n",
    "img_channel=3\n",
    "vqae = VQAE(n_hiddens, n_residual_hiddens, n_residual_layers,\n",
    "                n_embeddings, embedding_dim, \n",
    "                beta, img_channel).to(device)\n",
    "checkpoint = torch.load(\"../best_checkpoint/final/55-vqae-0.04753296934928414.pt\", map_location=torch.device('cpu'))\n",
    "vqae.load_state_dict(checkpoint)\n",
    "for param in vqae.parameters():\n",
    "    param.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d71b4e1-f1fe-4dcf-9ff7-d4ccd7188208",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_data = 'data20_right'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414c8ebe-a4b4-40b2-822c-41be77e38cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmeans_5_cluster\\\\MARL_data00_left_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\MARL_data00_right_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\MARL_data10_left_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\MARL_data10_right_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\MARL_data20_left_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\MARL_data20_right_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\VQAE_data00_left_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\VQAE_data00_right_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\VQAE_data10_left_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\VQAE_data10_right_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\VQAE_data20_left_5cluster_area_aggregation.csv',\n",
       " 'kmeans_5_cluster\\\\VQAE_data20_right_5cluster_area_aggregation.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = 'kmeans_5_cluster'\n",
    "files_to_process = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('area_aggregation.csv'):\n",
    "        files_to_process.append(os.path.join(folder_path, filename))\n",
    "files_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc7c34-97f4-41f1-85a5-3d966e3b1018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "513916ff-bc5d-4650-89d4-a02831a3524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data00_left\n",
      "data00_right\n",
      "data10_left\n",
      "data10_right\n",
      "data20_left\n",
      "data20_right\n",
      "data00_left\n",
      "data00_right\n",
      "data10_left\n",
      "data10_right\n",
      "data20_left\n",
      "data20_right\n"
     ]
    }
   ],
   "source": [
    "for file_path in files_to_process:\n",
    "    curr_data = file_path.split(\"5_cluster_area\")[0].split('kmeans_5_cluster\\\\')[1].split('_5cluster')[0][5:]\n",
    "    print(curr_data)\n",
    "    floor = FloorPlanDataset(multi_scale=True, root=f'../data/data_root/{curr_data}/',\\\n",
    "                             data_config='../data/data_config/', preprocess=True)\n",
    "    \n",
    "    df = pd.read_csv(file_path, index_col=None)\n",
    "    df['index_png'] = df['index'].apply(lambda x: calculate_index_png(x))\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36dbc2-44cb-4854-adc5-5b4352c44be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
