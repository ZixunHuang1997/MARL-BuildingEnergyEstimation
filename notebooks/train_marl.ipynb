{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8adff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from model.VQAE import VQAE\n",
    "from model.MARL import MARL\n",
    "from utils import device, add_noise\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from data.FloorPlanLoader import *\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import json\n",
    "\n",
    "USE_MULTISCALE = True\n",
    "USE_MULTITASK = True\n",
    "\n",
    "#Reproducability Checks:\n",
    "random.seed(0) #Python\n",
    "torch.manual_seed(0) #Torch\n",
    "np.random.seed(0) #NumPy\n",
    "\n",
    "#Hyperparameter\n",
    "batch_size = 128\n",
    "n_hiddens = 32\n",
    "n_residual_hiddens = 32\n",
    "n_residual_layers = 1\n",
    "embedding_dim = 64\n",
    "n_embeddings = 218\n",
    "beta = .25\n",
    "lr = 3e-3\n",
    "epochs = 100\n",
    "noise=False\n",
    "noise_weight=0.05\n",
    "img_channel=3 if USE_MULTISCALE else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63817b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_marl(train_loader=None, validation_loader=None, \n",
    "               data_variance=None, val_len=None, year_label_num=None, category_num=None,\n",
    "               get_pretrain=True, use_multi_task=USE_MULTITASK):\n",
    "    \n",
    "    vqae = VQAE(n_hiddens, n_residual_hiddens, n_residual_layers,\n",
    "                n_embeddings, embedding_dim, \n",
    "                beta, img_channel).to(device)\n",
    "    if get_pretrain:\n",
    "        vqae.load_state_dict(torch.load(\"./best_checkpoint/la/uncategorized/45-vqae-0.03231103945937422.pt\"))\n",
    "\n",
    "    marl = MARL(vqae, USE_MULTITASK, year_label_num, category_num)\n",
    "    optimizer = torch.optim.Adam(marl.parameters(), lr=lr, amsgrad=False)\n",
    "    train_recon_error = train_height_error = train_age_error = train_usage_error = []\n",
    "    test_recon_error = test_height_error = test_age_error = test_usage_error = []\n",
    "\n",
    "\n",
    "    best_loss = 2\n",
    "    for epoch in range(0, epochs):\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            marl.train()\n",
    "            for data_dict in tepoch:\n",
    "                data = data_dict['image_tensor']\n",
    "                bs = data.shape[0]\n",
    "                data_no_noise = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if noise:\n",
    "                    data = add_noise(data_no_noise, noise_weight=noise_weight)\n",
    "                else:\n",
    "                    data = data_no_noise\n",
    "                pred = marl(data)\n",
    "\n",
    "                # recon loss\n",
    "                vq_loss, data_recon, perplexity = pred['vqae']\n",
    "                recon_error = F.mse_loss(data_recon, data) / data_variance\n",
    "                train_recon_error.append(recon_error.item())\n",
    "\n",
    "                if USE_MULTITASK:\n",
    "                    # height infer\n",
    "                    height_pred = pred['height']\n",
    "                    height_error = F.mse_loss(height_pred, data_dict['height'].to(device).view(bs,-1))\n",
    "                    train_height_error.append(height_error.item())\n",
    "                    # age infer\n",
    "                    age_pred = pred['age']\n",
    "                    labels = data_dict['age_label'].to(device).long()\n",
    "                    age_error = F.cross_entropy(age_pred, labels)*0.3\n",
    "                    train_age_error.append(age_error.item())\n",
    "                    # category infer\n",
    "                    category_pred = pred['category']\n",
    "                    labels = data_dict['cate_onehot'].to(device)\n",
    "                    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "                    category_error = criterion(category_pred, labels)*0.7\n",
    "                    train_usage_error.append(category_error.item())\n",
    "\n",
    "                loss = (recon_error + vq_loss) + height_error + age_error + category_error\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                tepoch.set_postfix(recon_error=float((recon_error+ vq_loss).detach().cpu()),\n",
    "                                   height_error=float(height_error.detach().cpu()),\n",
    "                                   age_error=float(age_error.detach().cpu()),\n",
    "                                   category_error=float(category_error.detach().cpu()))\n",
    "                \n",
    "        avg_loss = 0\n",
    "        marl.eval()\n",
    "        with torch.no_grad():\n",
    "            for data_dict in validation_loader:\n",
    "                data = data_dict['image_tensor']\n",
    "                bs = data.shape[0]\n",
    "                data = data.to(device)\n",
    "\n",
    "                pred = marl(data)\n",
    "                # recon loss\n",
    "                vq_loss, data_recon, perplexity = pred['vqae']\n",
    "                recon_error = F.mse_loss(data_recon, data) / data_variance\n",
    "                test_recon_error.append(recon_error.item())\n",
    "\n",
    "                if USE_MULTITASK:\n",
    "                    # height infer\n",
    "                    height_pred = pred['height']\n",
    "                    height_error = F.mse_loss(height_pred, data_dict['height'].to(device).view(bs,-1))\n",
    "                    test_height_error.append(height_error.item())\n",
    "                    # age infer\n",
    "                    age_pred = pred['age']\n",
    "                    labels = data_dict['age_label'].to(device).long()\n",
    "                    age_error = F.cross_entropy(age_pred, labels)*0.3\n",
    "                    test_age_error.append(age_error.item())\n",
    "                    # category infer\n",
    "                    category_pred = pred['category']\n",
    "                    labels = data_dict['cate_onehot'].to(device)\n",
    "                    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "                    category_error = criterion(category_pred, labels)*0.7\n",
    "                    test_usage_error.append(category_error.item())\n",
    "\n",
    "                loss = (recon_error.item() \\\n",
    "                        + height_error.item()\\\n",
    "                        + age_error.item()\\\n",
    "                        + category_error.item()\\\n",
    "                        ) * batch_size\n",
    "                avg_loss += loss / val_len\n",
    "                \n",
    "                \n",
    "        if epoch%5==0 and avg_loss<best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(marl.state_dict(), f\"./checkpoint/{best_epoch}-vqae-{best_loss}.pt\")\n",
    "            torch.save(optimizer.state_dict(), f\"./checkpoint/{best_epoch}-adam-{best_loss}.pt\")\n",
    "            if USE_MULTITASK:\n",
    "                error = {\n",
    "                    'train_recon_error': train_recon_error,\n",
    "                    'train_height_error': train_height_error,\n",
    "                    'train_age_error': train_age_error,\n",
    "                    'train_usage_error': train_usage_error,\n",
    "                    'test_recon_error': test_recon_error,\n",
    "                    'test_height_error': test_height_error,\n",
    "                    'test_age_error': test_age_error,\n",
    "                    'test_usage_error': test_usage_error\n",
    "                }\n",
    "            else:\n",
    "                error = {\n",
    "                    'train_recon_error': train_recon_error,\n",
    "                    'test_recon_error': test_recon_error\n",
    "                }\n",
    "            with open(f\"./checkpoint/{best_epoch}-error-{best_loss}.json\", 'w', encoding ='utf8') as json_file:\n",
    "                json.dump(error, json_file, ensure_ascii = False)\n",
    "\n",
    "        print(f'Validation Loss: {avg_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "floor = FloorPlanDataset(multi_scale=True, root='./data/data_root/data00/', data_config='./data/data_config/', preprocess=True)\n",
    "data_variance = floor.var\n",
    "val_len = int(len(floor)/10)\n",
    "train_set, val_set = torch.utils.data.random_split(floor, [len(floor)-val_len, val_len])\n",
    "\n",
    "print(f\"data shape: {floor[0]['image_tensor'].shape}, dataset size: {len(floor)}, data variance: {data_variance}\")\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "validation_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch190",
   "language": "python",
   "name": "torch190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
