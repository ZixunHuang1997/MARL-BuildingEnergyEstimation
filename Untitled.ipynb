{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abe669ec-8b29-4577-ad8f-f9ad5687585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "469e9c78-4077-4d6e-a2e6-4c769bbf2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "# Data utils\n",
    "class Centeralize(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple): Desired output size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        tmp = image\n",
    "        image = torch.sum(image, dim=0)/3\n",
    "        h, w = image.shape\n",
    "        half_h = half_w = int(self.output_size/2)\n",
    "        grid_x = torch.FloatTensor([[i for i in range(0,w)] for j in range(0,h)])\n",
    "        grid_y = torch.FloatTensor([[j for i in range(0,w)] for j in range(0,h)])\n",
    "        img_reverse = (image<1).float()\n",
    "        center_w = int(torch.sum(img_reverse*grid_x)/torch.sum(img_reverse))\n",
    "        center_h = int(torch.sum(img_reverse*grid_y)/torch.sum(img_reverse))\n",
    "        top = center_h - half_h\n",
    "        left = center_w - half_w\n",
    "        image = tmp[:, top: top + self.output_size,\n",
    "                      left: left + self.output_size]\n",
    "        return image\n",
    "\n",
    "def preprocess_data(data_root):\n",
    "    composed = transforms.Compose([\n",
    "                                    Centeralize(1000),\n",
    "                                    transforms.Normalize((0.5,0.5,0.5), (1.0,1.0,1.0)),\n",
    "                                    transforms.Grayscale(1),\n",
    "                                    transforms.Resize(112),\n",
    "                                    transforms.CenterCrop(56),\n",
    "                                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84390745-8acb-4fec-b9b9-f16d0fb0dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data('data/data_root/zone_1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "853614f5-79d0-4cf8-89f5-d94393d97332",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "saveto() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m composed_transform \u001b[38;5;241m=\u001b[39m preprocess_data(data_root)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, png_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(png_files):\n\u001b[1;32m----> 8\u001b[0m     \u001b[43msaveto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpng_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomposed_transform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: saveto() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "data_root = 'data/data_root/zone_1_1'\n",
    "png_files = ['image1.png', 'image2.png', 'image3.png']  # List of .png file names\n",
    "\n",
    "composed_transform = preprocess_data(data_root)\n",
    "\n",
    "for i, png_file in enumerate(png_files):\n",
    "    saveto(png_file, data_root, i, composed_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccf42b54-8e57-4044-adbe-bb7a4cba96e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/data_root/zone_3_4/0.png'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read all data path\n",
    "data_root = 'data/data_root/zone_3_4/'\n",
    "all_file_names = os.listdir(data_root)\n",
    "all_data_dirs = []\n",
    "for name in all_file_names:\n",
    "    if name.endswith(\".png\"):\n",
    "        all_data_dirs.append(data_root + name)\n",
    "all_data_dirs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63b979de-f70d-4dfd-ae56-58f43ba1142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'999.png'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8485941-650e-48cf-8c27-eff88feff09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveto(item, data_root, i):\n",
    "    img = Image.open(item)\n",
    "    img = np.array(img)/255.0\n",
    "    img = np.transpose(img[:, :, :3], (2, 0, 1))\n",
    "    img_tensor = torch.from_numpy(img.astype(np.float32))\n",
    "    torch.save(composed(img_tensor), data_root +'/'+ str(i) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e891e245-4fc9-4287-97f5-a177c157fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transforms.Compose([\n",
    "                                Centeralize(1000),\n",
    "                                transforms.Normalize((0.5,0.5,0.5), (1.0,1.0,1.0)),\n",
    "                                transforms.Grayscale(1),\n",
    "                                transforms.Resize(112),\n",
    "                                transforms.CenterCrop(56),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3e7df41-ed19-4c9c-b124-43359cf8d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for item in all_data_dirs:\n",
    "    try:\n",
    "        saveto(item, data_root, i)\n",
    "    except:\n",
    "        pass\n",
    "    i+=1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "640b8836-ba61-42be-8362-6efc2631e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7478/7478 [1:12:51<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for item in tqdm(all_data_dirs):\n",
    "    saveto(item, data_root, i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0770738e-8bf9-4383-9ac7-2740f9bfe68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7664"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb31eb6-aa72-4492-a8f6-08efd4c951dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
